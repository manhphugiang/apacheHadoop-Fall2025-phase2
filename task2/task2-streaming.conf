# Define agent, source, sink and channel names
agent1.sources = source1
agent1.sinks = sink1
agent1.channels = channel1

# Bind the channel to the source and sink
agent1.sources.source1.channels = channel1
agent1.sinks.sink1.channel = channel1

# Define the source - separate directory from Task 1
agent1.sources.source1.type = spooldir
agent1.sources.source1.spoolDir = /home/hadoopuser/flume_streaming_spooldir

# Define the sink with fallback path
agent1.sinks.sink1.type = hdfs
agent1.sinks.sink1.hdfs.path = hdfs://192.168.56.5:9820/projectPhase2-v6/%{year|unknown}/%{month|unknown}/%{day|unknown}
agent1.sinks.sink1.hdfs.filePrefix = stream_data
agent1.sinks.sink1.hdfs.writeFormat = Text
agent1.sinks.sink1.hdfs.fileType = DataStream
agent1.sinks.sink1.hdfs.rollInterval = 60
agent1.sinks.sink1.hdfs.useLocalTimeStamp = false

# Define the interceptor(s) in order of processing
agent1.sources.source1.interceptors = i1

# i1 â€“ regex extractor interceptor; extract date from CONDATE column (3rd column)
agent1.sources.source1.interceptors.i1.type = regex_extractor
agent1.sources.source1.interceptors.i1.regex = ^[^\t]*\t[^\t]*\t(\d{4})-(\d{2})-(\d{2})\t.*
agent1.sources.source1.interceptors.i1.serializers = s1 s2 s3
agent1.sources.source1.interceptors.i1.serializers.s1.name = year
agent1.sources.source1.interceptors.i1.serializers.s2.name = month  
agent1.sources.source1.interceptors.i1.serializers.s3.name = day

# Use channel type memory for high throughput and few console messages. It is volatile, and messages can be lost.
agent1.channels.channel1.type = memory

# -- end of configuration file
